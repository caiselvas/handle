{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cai Selvas Sala\\GIA_UPC\\Personal\\DatathonFME\\Datathon 2024\\handle\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from src.custom_inference_dataset import CustomInferenceDataset\n",
    "from src.handler import Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/x_num_categories_list.pkl', 'rb') as f:\n",
    "\tx_num_categories_list = pickle.load(f)\n",
    "\n",
    "with open('./data/y_num_categories_list.pkl', 'rb') as f:\n",
    "\ty_num_categories_list = pickle.load(f)\n",
    "\n",
    "with open('./data/label_encoders.pkl', 'rb') as f:\n",
    "\tlabel_encoders = pickle.load(f)\n",
    "\n",
    "with open('./data/onehot_encoders.pkl', 'rb') as f:\n",
    "\tonehot_encoders = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cai Selvas Sala\\AppData\\Local\\Temp\\ipykernel_6820\\414790742.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./models/best_model.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Handler(\n",
       "  (image_encoder): ImageEncoder(\n",
       "    (model): CLIPModel(\n",
       "      (text_model): CLIPTextTransformer(\n",
       "        (embeddings): CLIPTextEmbeddings(\n",
       "          (token_embedding): Embedding(49408, 512)\n",
       "          (position_embedding): Embedding(77, 512)\n",
       "        )\n",
       "        (encoder): CLIPEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-11): 12 x CLIPEncoderLayer(\n",
       "              (self_attn): CLIPSdpaAttention(\n",
       "                (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (vision_model): CLIPVisionTransformer(\n",
       "        (embeddings): CLIPVisionEmbeddings(\n",
       "          (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "          (position_embedding): Embedding(50, 768)\n",
       "        )\n",
       "        (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder): CLIPEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-11): 12 x CLIPEncoderLayer(\n",
       "              (self_attn): CLIPSdpaAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): CLIPMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "      (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (tabular_encoder): TabularEncoder(\n",
       "    (embeddings): ModuleList(\n",
       "      (0): Embedding(3, 512)\n",
       "      (1): Embedding(5, 512)\n",
       "      (2): Embedding(3, 512)\n",
       "      (3): Embedding(7, 512)\n",
       "      (4): Embedding(5, 512)\n",
       "      (5): Embedding(26, 512)\n",
       "      (6): Embedding(47, 512)\n",
       "      (7): Embedding(122, 512)\n",
       "    )\n",
       "    (transformer_layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (layer_norms): ModuleList(\n",
       "      (0-1): 2 x LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multimodal_interaction): MultimodalInteraction(\n",
       "    (cross_attention_layers): ModuleList(\n",
       "      (0-1): 2 x MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (feed_forward_layers): ModuleList(\n",
       "      (0-1): 2 x Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norms_attn): ModuleList(\n",
       "      (0-1): 2 x LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layer_norms_ff): ModuleList(\n",
       "      (0-1): 2 x LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (output_layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=512, out_features=7, bias=True)\n",
       "      (2): Linear(in_features=512, out_features=12, bias=True)\n",
       "      (3): Linear(in_features=512, out_features=9, bias=True)\n",
       "      (4): Linear(in_features=512, out_features=13, bias=True)\n",
       "      (5-6): 2 x Linear(in_features=512, out_features=34, bias=True)\n",
       "      (7): Linear(in_features=512, out_features=7, bias=True)\n",
       "      (8-10): 3 x Linear(in_features=512, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Handler(x_num_categories_list=x_num_categories_list, y_num_categories_list=y_num_categories_list)\n",
    "\n",
    "model.load_state_dict(torch.load('./models/best_model.pth', map_location=device))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder_path = './data/archive/images/images'\n",
    "x_test_file_path = './data/x_test.csv'\n",
    "y_data_file_path = './data/y_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_csv(x_test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = pd.read_csv(y_data_file_path).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = x_test.drop_duplicates(subset='des_filename', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomInferenceDataset(data=tmp, image_folder_path=image_folder_path, label_encoders=label_encoders, onehot_encoders=onehot_encoders)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1/6529\n",
      "Prediction 2/6529\n",
      "Prediction 3/6529\n",
      "Prediction 4/6529\n",
      "Prediction 5/6529\n",
      "Prediction 6/6529\n",
      "Prediction 7/6529\n",
      "Prediction 8/6529\n",
      "Prediction 9/6529\n",
      "Prediction 10/6529\n",
      "Prediction 11/6529\n",
      "Prediction 12/6529\n",
      "Prediction 13/6529\n",
      "Prediction 14/6529\n",
      "Prediction 15/6529\n",
      "Prediction 16/6529\n",
      "Prediction 17/6529\n",
      "Prediction 18/6529\n",
      "Prediction 19/6529\n",
      "Prediction 20/6529\n",
      "Prediction 21/6529\n",
      "Prediction 22/6529\n",
      "Prediction 23/6529\n",
      "Prediction 24/6529\n",
      "Prediction 25/6529\n",
      "Prediction 26/6529\n",
      "Prediction 27/6529\n",
      "Prediction 28/6529\n",
      "Prediction 29/6529\n",
      "Prediction 30/6529\n",
      "Prediction 31/6529\n",
      "Prediction 32/6529\n",
      "Prediction 33/6529\n",
      "Prediction 34/6529\n",
      "Prediction 35/6529\n",
      "Prediction 36/6529\n",
      "Prediction 37/6529\n",
      "Prediction 38/6529\n",
      "Prediction 39/6529\n",
      "Prediction 40/6529\n",
      "Prediction 41/6529\n",
      "Prediction 42/6529\n",
      "Prediction 43/6529\n",
      "Prediction 44/6529\n",
      "Prediction 45/6529\n",
      "Prediction 46/6529\n",
      "Prediction 47/6529\n",
      "Prediction 48/6529\n",
      "Prediction 49/6529\n",
      "Prediction 50/6529\n",
      "Prediction 51/6529\n",
      "Prediction 52/6529\n",
      "Prediction 53/6529\n",
      "Prediction 54/6529\n",
      "Prediction 55/6529\n",
      "Prediction 56/6529\n",
      "Prediction 57/6529\n",
      "Prediction 58/6529\n",
      "Prediction 59/6529\n",
      "Prediction 60/6529\n",
      "Prediction 61/6529\n",
      "Prediction 62/6529\n",
      "Prediction 63/6529\n",
      "Prediction 64/6529\n",
      "Prediction 65/6529\n",
      "Prediction 66/6529\n",
      "Prediction 67/6529\n",
      "Prediction 68/6529\n",
      "Prediction 69/6529\n",
      "Prediction 70/6529\n",
      "Prediction 71/6529\n",
      "Prediction 72/6529\n",
      "Prediction 73/6529\n",
      "Prediction 74/6529\n",
      "Prediction 75/6529\n",
      "Prediction 76/6529\n",
      "Prediction 77/6529\n",
      "Prediction 78/6529\n",
      "Prediction 79/6529\n",
      "Prediction 80/6529\n",
      "Prediction 81/6529\n",
      "Prediction 82/6529\n",
      "Prediction 83/6529\n",
      "Prediction 84/6529\n",
      "Prediction 85/6529\n",
      "Prediction 86/6529\n",
      "Prediction 87/6529\n",
      "Prediction 88/6529\n",
      "Prediction 89/6529\n",
      "Prediction 90/6529\n",
      "Prediction 91/6529\n",
      "Prediction 92/6529\n",
      "Prediction 93/6529\n",
      "Prediction 94/6529\n",
      "Prediction 95/6529\n",
      "Prediction 96/6529\n",
      "Prediction 97/6529\n",
      "Prediction 98/6529\n",
      "Prediction 99/6529\n",
      "Prediction 100/6529\n",
      "Prediction 101/6529\n",
      "Prediction 102/6529\n",
      "Prediction 103/6529\n",
      "Prediction 104/6529\n",
      "Prediction 105/6529\n",
      "Prediction 106/6529\n",
      "Prediction 107/6529\n",
      "Prediction 108/6529\n",
      "Prediction 109/6529\n",
      "Prediction 110/6529\n",
      "Prediction 111/6529\n",
      "Prediction 112/6529\n",
      "Prediction 113/6529\n",
      "Prediction 114/6529\n",
      "Prediction 115/6529\n",
      "Prediction 116/6529\n",
      "Prediction 117/6529\n",
      "Prediction 118/6529\n",
      "Prediction 119/6529\n",
      "Prediction 120/6529\n",
      "Prediction 121/6529\n",
      "Prediction 122/6529\n",
      "Prediction 123/6529\n",
      "Prediction 124/6529\n",
      "Prediction 125/6529\n",
      "Prediction 126/6529\n",
      "Prediction 127/6529\n",
      "Prediction 128/6529\n",
      "Prediction 129/6529\n",
      "Prediction 130/6529\n",
      "Prediction 131/6529\n",
      "Prediction 132/6529\n",
      "Prediction 133/6529\n",
      "Prediction 134/6529\n",
      "Prediction 135/6529\n",
      "Prediction 136/6529\n",
      "Prediction 137/6529\n",
      "Prediction 138/6529\n",
      "Prediction 139/6529\n",
      "Prediction 140/6529\n",
      "Prediction 141/6529\n",
      "Prediction 142/6529\n",
      "Prediction 143/6529\n",
      "Prediction 144/6529\n",
      "Prediction 145/6529\n",
      "Prediction 146/6529\n",
      "Prediction 147/6529\n",
      "Prediction 148/6529\n",
      "Prediction 149/6529\n",
      "Prediction 150/6529\n",
      "Prediction 151/6529\n",
      "Prediction 152/6529\n",
      "Prediction 153/6529\n",
      "Prediction 154/6529\n",
      "Prediction 155/6529\n",
      "Prediction 156/6529\n",
      "Prediction 157/6529\n",
      "Prediction 158/6529\n",
      "Prediction 159/6529\n",
      "Prediction 160/6529\n",
      "Prediction 161/6529\n",
      "Prediction 162/6529\n",
      "Prediction 163/6529\n",
      "Prediction 164/6529\n",
      "Prediction 165/6529\n",
      "Prediction 166/6529\n",
      "Prediction 167/6529\n",
      "Prediction 168/6529\n",
      "Prediction 169/6529\n",
      "Prediction 170/6529\n",
      "Prediction 171/6529\n",
      "Prediction 172/6529\n",
      "Prediction 173/6529\n",
      "Prediction 174/6529\n",
      "Prediction 175/6529\n",
      "Prediction 176/6529\n",
      "Prediction 177/6529\n",
      "Prediction 178/6529\n",
      "Prediction 179/6529\n",
      "Prediction 180/6529\n",
      "Prediction 181/6529\n",
      "Prediction 182/6529\n",
      "Prediction 183/6529\n",
      "Prediction 184/6529\n",
      "Prediction 185/6529\n",
      "Prediction 186/6529\n",
      "Prediction 187/6529\n",
      "Prediction 188/6529\n",
      "Prediction 189/6529\n",
      "Prediction 190/6529\n",
      "Prediction 191/6529\n",
      "Prediction 192/6529\n",
      "Prediction 193/6529\n",
      "Prediction 194/6529\n",
      "Prediction 195/6529\n",
      "Prediction 196/6529\n",
      "Prediction 197/6529\n",
      "Prediction 198/6529\n",
      "Prediction 199/6529\n",
      "Prediction 200/6529\n",
      "Prediction 201/6529\n",
      "Prediction 202/6529\n",
      "Prediction 203/6529\n",
      "Prediction 204/6529\n",
      "Prediction 205/6529\n",
      "Prediction 206/6529\n",
      "Prediction 207/6529\n",
      "Prediction 208/6529\n",
      "Prediction 209/6529\n",
      "Prediction 210/6529\n",
      "Prediction 211/6529\n",
      "Prediction 212/6529\n",
      "Prediction 213/6529\n",
      "Prediction 214/6529\n",
      "Prediction 215/6529\n",
      "Prediction 216/6529\n",
      "Prediction 217/6529\n",
      "Prediction 218/6529\n",
      "Prediction 219/6529\n",
      "Prediction 220/6529\n",
      "Prediction 221/6529\n",
      "Prediction 222/6529\n",
      "Prediction 223/6529\n",
      "Prediction 224/6529\n",
      "Prediction 225/6529\n",
      "Prediction 226/6529\n",
      "Prediction 227/6529\n",
      "Prediction 228/6529\n",
      "Prediction 229/6529\n",
      "Prediction 230/6529\n",
      "Prediction 231/6529\n",
      "Prediction 232/6529\n",
      "Prediction 233/6529\n",
      "Prediction 234/6529\n",
      "Prediction 235/6529\n",
      "Prediction 236/6529\n",
      "Prediction 237/6529\n",
      "Prediction 238/6529\n",
      "Prediction 239/6529\n",
      "Prediction 240/6529\n",
      "Prediction 241/6529\n",
      "Prediction 242/6529\n",
      "Prediction 243/6529\n",
      "Prediction 244/6529\n",
      "Prediction 245/6529\n",
      "Prediction 246/6529\n",
      "Prediction 247/6529\n",
      "Prediction 248/6529\n",
      "Prediction 249/6529\n",
      "Prediction 250/6529\n",
      "Prediction 251/6529\n",
      "Prediction 252/6529\n",
      "Prediction 253/6529\n",
      "Prediction 254/6529\n",
      "Prediction 255/6529\n",
      "Prediction 256/6529\n",
      "Prediction 257/6529\n",
      "Prediction 258/6529\n",
      "Prediction 259/6529\n",
      "Prediction 260/6529\n",
      "Prediction 261/6529\n",
      "Prediction 262/6529\n",
      "Prediction 263/6529\n",
      "Prediction 264/6529\n",
      "Prediction 265/6529\n",
      "Prediction 266/6529\n",
      "Prediction 267/6529\n",
      "Prediction 268/6529\n",
      "Prediction 269/6529\n",
      "Prediction 270/6529\n",
      "Prediction 271/6529\n",
      "Prediction 272/6529\n",
      "Prediction 273/6529\n",
      "Prediction 274/6529\n",
      "Prediction 275/6529\n",
      "Prediction 276/6529\n",
      "Prediction 277/6529\n",
      "Prediction 278/6529\n",
      "Prediction 279/6529\n",
      "Prediction 280/6529\n",
      "Prediction 281/6529\n",
      "Prediction 282/6529\n",
      "Prediction 283/6529\n",
      "Prediction 284/6529\n",
      "Prediction 285/6529\n",
      "Prediction 286/6529\n",
      "Prediction 287/6529\n",
      "Prediction 288/6529\n",
      "Prediction 289/6529\n",
      "Prediction 290/6529\n",
      "Prediction 291/6529\n",
      "Prediction 292/6529\n",
      "Prediction 293/6529\n",
      "Prediction 294/6529\n",
      "Prediction 295/6529\n",
      "Prediction 296/6529\n",
      "Prediction 297/6529\n",
      "Prediction 298/6529\n",
      "Prediction 299/6529\n",
      "Prediction 300/6529\n",
      "Prediction 301/6529\n",
      "Prediction 302/6529\n",
      "Prediction 303/6529\n",
      "Prediction 304/6529\n",
      "Prediction 305/6529\n",
      "Prediction 306/6529\n",
      "Prediction 307/6529\n",
      "Prediction 308/6529\n",
      "Prediction 309/6529\n",
      "Prediction 310/6529\n",
      "Prediction 311/6529\n",
      "Prediction 312/6529\n",
      "Prediction 313/6529\n",
      "Prediction 314/6529\n",
      "Prediction 315/6529\n",
      "Prediction 316/6529\n",
      "Prediction 317/6529\n",
      "Prediction 318/6529\n",
      "Prediction 319/6529\n",
      "Prediction 320/6529\n",
      "Prediction 321/6529\n",
      "Prediction 322/6529\n",
      "Prediction 323/6529\n",
      "Prediction 324/6529\n",
      "Prediction 325/6529\n",
      "Prediction 326/6529\n",
      "Prediction 327/6529\n",
      "Prediction 328/6529\n",
      "Prediction 329/6529\n",
      "Prediction 330/6529\n",
      "Prediction 331/6529\n",
      "Prediction 332/6529\n",
      "Prediction 333/6529\n",
      "Prediction 334/6529\n",
      "Prediction 335/6529\n",
      "Prediction 336/6529\n",
      "Prediction 337/6529\n",
      "Prediction 338/6529\n",
      "Prediction 339/6529\n",
      "Prediction 340/6529\n",
      "Prediction 341/6529\n",
      "Prediction 342/6529\n",
      "Prediction 343/6529\n",
      "Prediction 344/6529\n",
      "Prediction 345/6529\n",
      "Prediction 346/6529\n",
      "Prediction 347/6529\n",
      "Prediction 348/6529\n",
      "Prediction 349/6529\n",
      "Prediction 350/6529\n",
      "Prediction 351/6529\n",
      "Prediction 352/6529\n",
      "Prediction 353/6529\n",
      "Prediction 354/6529\n",
      "Prediction 355/6529\n",
      "Prediction 356/6529\n",
      "Prediction 357/6529\n",
      "Prediction 358/6529\n",
      "Prediction 359/6529\n",
      "Prediction 360/6529\n",
      "Prediction 361/6529\n",
      "Prediction 362/6529\n",
      "Prediction 363/6529\n",
      "Prediction 364/6529\n",
      "Prediction 365/6529\n",
      "Prediction 366/6529\n",
      "Prediction 367/6529\n",
      "Prediction 368/6529\n",
      "Prediction 369/6529\n",
      "Prediction 370/6529\n",
      "Prediction 371/6529\n",
      "Prediction 372/6529\n",
      "Prediction 373/6529\n",
      "Prediction 374/6529\n",
      "Prediction 375/6529\n",
      "Prediction 376/6529\n",
      "Prediction 377/6529\n",
      "Prediction 378/6529\n",
      "Prediction 379/6529\n",
      "Prediction 380/6529\n",
      "Prediction 381/6529\n",
      "Prediction 382/6529\n",
      "Prediction 383/6529\n",
      "Prediction 384/6529\n",
      "Prediction 385/6529\n",
      "Prediction 386/6529\n",
      "Prediction 387/6529\n",
      "Prediction 388/6529\n",
      "Prediction 389/6529\n",
      "Prediction 390/6529\n",
      "Prediction 391/6529\n",
      "Prediction 392/6529\n",
      "Prediction 393/6529\n",
      "Prediction 394/6529\n",
      "Prediction 395/6529\n",
      "Prediction 396/6529\n",
      "Prediction 397/6529\n",
      "Prediction 398/6529\n",
      "Prediction 399/6529\n",
      "Prediction 400/6529\n",
      "Prediction 401/6529\n",
      "Prediction 402/6529\n",
      "Prediction 403/6529\n",
      "Prediction 404/6529\n",
      "Prediction 405/6529\n",
      "Prediction 406/6529\n",
      "Prediction 407/6529\n",
      "Prediction 408/6529\n",
      "Prediction 409/6529\n",
      "Prediction 410/6529\n",
      "Prediction 411/6529\n",
      "Prediction 412/6529\n",
      "Prediction 413/6529\n",
      "Prediction 414/6529\n",
      "Prediction 415/6529\n",
      "Prediction 416/6529\n",
      "Prediction 417/6529\n",
      "Prediction 418/6529\n",
      "Prediction 419/6529\n",
      "Prediction 420/6529\n",
      "Prediction 421/6529\n",
      "Prediction 422/6529\n",
      "Prediction 423/6529\n",
      "Prediction 424/6529\n",
      "Prediction 425/6529\n",
      "Prediction 426/6529\n",
      "Prediction 427/6529\n",
      "Prediction 428/6529\n",
      "Prediction 429/6529\n",
      "Prediction 430/6529\n",
      "Prediction 431/6529\n",
      "Prediction 432/6529\n",
      "Prediction 433/6529\n",
      "Prediction 434/6529\n",
      "Prediction 435/6529\n",
      "Prediction 436/6529\n",
      "Prediction 437/6529\n",
      "Prediction 438/6529\n",
      "Prediction 439/6529\n",
      "Prediction 440/6529\n",
      "Prediction 441/6529\n",
      "Prediction 442/6529\n",
      "Prediction 443/6529\n",
      "Prediction 444/6529\n",
      "Prediction 445/6529\n",
      "Prediction 446/6529\n",
      "Prediction 447/6529\n",
      "Prediction 448/6529\n",
      "Prediction 449/6529\n",
      "Prediction 450/6529\n",
      "Prediction 451/6529\n",
      "Prediction 452/6529\n",
      "Prediction 453/6529\n",
      "Prediction 454/6529\n",
      "Prediction 455/6529\n",
      "Prediction 456/6529\n",
      "Prediction 457/6529\n",
      "Prediction 458/6529\n",
      "Prediction 459/6529\n",
      "Prediction 460/6529\n",
      "Prediction 461/6529\n",
      "Prediction 462/6529\n",
      "Prediction 463/6529\n",
      "Prediction 464/6529\n",
      "Prediction 465/6529\n",
      "Prediction 466/6529\n"
     ]
    }
   ],
   "source": [
    "# Inicializa una lista para almacenar los resultados\n",
    "results = []\n",
    "\n",
    "# Itera sobre el test_loader para obtener imágenes, datos tabulares y prefijos de imagen\n",
    "for i, (image, tabular_data, image_prefix) in enumerate(test_loader):\n",
    "    image = image.to(device)\n",
    "    tabular_data = tabular_data.to(device)\n",
    "    image_prefix = image_prefix[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            # Realiza las predicciones\n",
    "            predictions = model(image, tabular_data)\n",
    "            print(f\"Prediction {i + 1}/{len(test_loader)}\")\n",
    "\n",
    "            # Itera sobre cada predicción y etiqueta para calcular los vectores one-hot\n",
    "            for pred, atr in zip(predictions, y_labels):\n",
    "\n",
    "                # Elimina dimensiones innecesarias si `pred` tiene dimensiones adicionales\n",
    "                if pred.dim() > 1:\n",
    "                    pred = pred.squeeze(0)  # Redimensiona si es necesario\n",
    "\n",
    "                # Crear un vector one-hot para el índice predicho\n",
    "                onehot_vector = torch.zeros_like(pred)\n",
    "\n",
    "                # Encuentra el índice de la predicción más alta\n",
    "                pred_index = torch.argmax(pred).item()  # Convierte a un número entero\n",
    "\n",
    "                # Establece el índice predicho en 1\n",
    "                onehot_vector[pred_index] = 1\n",
    "\n",
    "                # Decodifica el valor de la clase predicha\n",
    "                pred_value = dataset.value_from_onehot_encoder(atr, onehot_vector)\n",
    "\n",
    "                # Agrega el resultado a la lista\n",
    "                results.append({'test_id': f\"{image_prefix}_{atr}\", 'des_value': pred_value})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error predicting for test_id {image_prefix}. Error message: {e}')\n",
    "            # En caso de error, agrega 'INVALID' para cada atributo\n",
    "            for atr in y_labels:\n",
    "                results.append({'test_id': f\"{image_prefix}_{atr}\", 'des_value': 'INVALID'})\n",
    "            continue\n",
    "\n",
    "# Convierte la lista de resultados en un DataFrame\n",
    "resulting_df = pd.DataFrame(results)\n",
    "\n",
    "# Lee los test_ids únicos desde el archivo de ejemplo\n",
    "example_results = pd.read_csv('./data/archive/sample_submission.csv')\n",
    "unique_test_ids = example_results['test_id'].unique()\n",
    "\n",
    "# Filtra el DataFrame para mantener solo los IDs de prueba únicos\n",
    "resulting_df = resulting_df[resulting_df['test_id'].isin(unique_test_ids)]\n",
    "\n",
    "# Guarda el DataFrame resultante en un archivo CSV\n",
    "resulting_df.to_csv('./data/test_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
