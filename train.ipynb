{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.custom_dataset import CustomDataset\n",
    "from src.handler import Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data_path = './data/archive/images/images'\n",
    "x_train_file_path = './data/x_train.csv'\n",
    "y_train_file_path = './data/y_train.csv'\n",
    "x_val_file_path = './data/x_val.csv'\n",
    "y_val_file_path = './data/y_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 2\n",
    "checkpoint_interval = 200\n",
    "validation_check_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_path=x_train_file_path, y_path=y_train_file_path, image_folder_path=images_data_path)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "x_num_categories_list=train_dataset.get_x_num_categories_list()\n",
    "y_num_categories_list=train_dataset.get_y_num_categories_list()\n",
    "\n",
    "val_dataset = CustomDataset(x_path=x_val_file_path, y_path=y_val_file_path, image_folder_path=images_data_path)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 1e-3\n",
    "min_lr = 1e-5\n",
    "weight_decay_value = 1e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = Handler(x_num_categories_list=x_num_categories_list, y_num_categories_list=y_num_categories_list)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=weight_decay_value)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop with validation and weight decay\n",
    "best_accuracy = 0.0\n",
    "best_weights = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Training phase\n",
    "    for batch_idx, (images, tabular_data, labels) in enumerate(train_data_loader):\n",
    "        # Move data to GPU if available\n",
    "        images, tabular_data = images.to(device), tabular_data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if labels.dim() == 2 and labels.size(1) > 1:  # Convert one-hot to indices if necessary\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images, tabular_data)\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        # Save model checkpoint periodically\n",
    "        if (total_samples + 1) % checkpoint_interval == 0:\n",
    "            checkpoint_path = f'model_checkpoint_{total_samples}.pth'\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Checkpoint saved at '{checkpoint_path}' for {total_samples} samples.\")\n",
    "        \n",
    "        # Print training stats every 10 batches\n",
    "        if batch_idx % 10 == 0:\n",
    "            batch_accuracy = 100 * correct_predictions / total_samples\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_data_loader)}], \"\n",
    "                  f\"Loss: {loss.item():.4f}, Batch Accuracy: {batch_accuracy:.2f}%\")\n",
    "\n",
    "        # Validation evaluation every 200 steps\n",
    "        if (batch_idx + 1) % validation_check_steps == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct_predictions = 0\n",
    "            val_total_samples = 0\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_tabular_data, val_labels in val_data_loader:\n",
    "                    val_images, val_tabular_data, val_labels = (\n",
    "                        val_images.to(device), \n",
    "                        val_tabular_data.to(device), \n",
    "                        val_labels.to(device)\n",
    "                    )\n",
    "                    if val_labels.dim() == 2 and val_labels.size(1) > 1:\n",
    "                        val_labels = torch.argmax(val_labels, dim=1)\n",
    "\n",
    "                    val_outputs = model(val_images, val_tabular_data)\n",
    "                    val_outputs = torch.cat(val_outputs, dim=1)\n",
    "\n",
    "                    # Calculate loss\n",
    "                    val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "                    # Calculate accuracy\n",
    "                    _, val_predicted = torch.max(val_outputs, 1)\n",
    "                    val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "                    val_total_samples += val_labels.size(0)\n",
    "\n",
    "            # Average validation loss and accuracy\n",
    "            val_loss /= len(val_data_loader)\n",
    "            val_accuracy = 100 * val_correct_predictions / val_total_samples\n",
    "            print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "            # Save the best model weights based on validation accuracy\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "                best_weights = model.state_dict().copy()\n",
    "                torch.save(best_weights, './models/best_model.pth')\n",
    "                print(\"New best model saved as './models/best_model.pth'\")\n",
    "            model.train()  # Return to training mode\n",
    "\n",
    "    # Epoch-level loss and accuracy\n",
    "    epoch_loss = running_loss / len(train_data_loader)\n",
    "    epoch_accuracy = 100 * correct_predictions / total_samples\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed: Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "    \n",
    "    # Update the scheduler for learning rate decay\n",
    "    scheduler.step()\n",
    "\n",
    "# Save the final model weights\n",
    "torch.save(model.state_dict(), './models/final_model.pth')\n",
    "print(\"Final model saved as './models/final_model.pth'\")\n",
    "\n",
    "# Ensure best weights are also saved\n",
    "if best_weights is not None:\n",
    "    torch.save(best_weights, './models/best_model.pth')\n",
    "    print(\"Best model saved as './models/best_model.pth'\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
