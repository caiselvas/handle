{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "\n",
    "from src.custom_dataset import CustomDataset\n",
    "from src.handler import Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data_path = './data/archive/images/images'\n",
    "x_train_file_path = './data/x_train.csv'\n",
    "y_train_file_path = './data/y_train.csv'\n",
    "x_val_file_path = './data/x_val.csv'\n",
    "y_val_file_path = './data/y_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "num_epochs = 2\n",
    "checkpoint_interval = 200\n",
    "validation_check_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_path=x_train_file_path, y_path=y_train_file_path, image_folder_path=images_data_path)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = CustomDataset(x_path=x_val_file_path, y_path=y_val_file_path, image_folder_path=images_data_path)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num_categories_list=train_dataset.get_x_num_categories_list()\n",
    "y_num_categories_list=train_dataset.get_y_num_categories_list()\n",
    "label_encoders = train_dataset.get_label_encoders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/label_encoders.pkl', 'wb') as f:\n",
    "\tpickle.dump(label_encoders, f)\n",
    "\n",
    "with open('./data/x_num_categories_list.pkl', 'wb') as f:\n",
    "\tpickle.dump(x_num_categories_list, f)\n",
    "\n",
    "with open('./data/y_num_categories_list.pkl', 'wb') as f:\n",
    "\tpickle.dump(y_num_categories_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 1e-3\n",
    "min_lr = 1e-5\n",
    "weight_decay_value = 1e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = Handler(x_num_categories_list=x_num_categories_list, y_num_categories_list=y_num_categories_list)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=weight_decay_value)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop with validation and weight decay\n",
    "best_accuracy = 0.0\n",
    "best_weights = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tmodel.train()\n",
    "\trunning_loss = 0.0\n",
    "\tcorrect_predictions = 0\n",
    "\ttotal_samples = 0\n",
    "\t\n",
    "\t# Training phase\n",
    "\tfor batch_idx, (images, tabular_data, labels) in enumerate(train_data_loader):\n",
    "\t\t# Move data to GPU if available\n",
    "\t\timages, tabular_data = images.to(device), tabular_data.to(device)\n",
    "\t\tlabels = labels.to(device)\n",
    "\t\tif labels.dim() == 2 and labels.size(1) > 1:  # Convert one-hot to indices if necessary\n",
    "\t\t\tlabels = torch.argmax(labels, dim=1)\n",
    "\n",
    "\t\t# Zero the gradients\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\t\n",
    "\t\t# Forward pass\n",
    "\t\toutputs = model(images, tabular_data)\n",
    "\t\toutputs = torch.cat(outputs, dim=1)\n",
    "\t\t\n",
    "\t\t# Calculate loss\n",
    "\t\tloss = criterion(outputs, labels)\n",
    "\t\t\n",
    "\t\t# Backward pass and optimize\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\t# Update running loss\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\t\n",
    "\t\t# Calculate accuracy\n",
    "\t\t_, predicted = torch.max(outputs, 1)\n",
    "\t\tcorrect_predictions += (predicted == labels).sum().item()\n",
    "\t\ttotal_samples += labels.size(0)\n",
    "\t\t\n",
    "\t\t# # Save model checkpoint periodically\n",
    "\t\t# if (total_samples + 1) % checkpoint_interval == 0:\n",
    "\t\t# \tcheckpoint_path = f'model_checkpoint_{total_samples}.pth'\n",
    "\t\t# \ttorch.save(model.state_dict(), checkpoint_path)\n",
    "\t\t# \tprint(f\"Checkpoint saved at '{checkpoint_path}' for {total_samples} samples.\")\n",
    "\t\t\n",
    "\t\t# Print training stats every step\n",
    "\t\tbatch_accuracy = 100 * correct_predictions / total_samples\n",
    "\t\tprint(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_data_loader)}], \"\n",
    "\t\t\t\tf\"Loss: {loss.item():.4f}, Batch Accuracy: {batch_accuracy:.2f}%\")\n",
    "\n",
    "\t\t# Validation evaluation every validation_check_steps steps\n",
    "\t\tif (batch_idx + 1) % validation_check_steps == 0:\n",
    "\t\t\tmodel.eval()\n",
    "\t\t\tval_loss = 0.0\n",
    "\t\t\tval_correct_predictions = 0\n",
    "\t\t\tval_total_samples = 0\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tfor val_images, val_tabular_data, val_labels in val_data_loader:\n",
    "\t\t\t\t\tval_images, val_tabular_data, val_labels = (\n",
    "\t\t\t\t\t\tval_images.to(device), \n",
    "\t\t\t\t\t\tval_tabular_data.to(device), \n",
    "\t\t\t\t\t\tval_labels.to(device)\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\tif val_labels.dim() == 2 and val_labels.size(1) > 1:\n",
    "\t\t\t\t\t\tval_labels = torch.argmax(val_labels, dim=1)\n",
    "\n",
    "\t\t\t\t\tval_outputs = model(val_images, val_tabular_data)\n",
    "\t\t\t\t\tval_outputs = torch.cat(val_outputs, dim=1)\n",
    "\n",
    "\t\t\t\t\t# Calculate loss\n",
    "\t\t\t\t\tval_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "\t\t\t\t\t# Calculate accuracy\n",
    "\t\t\t\t\t_, val_predicted = torch.max(val_outputs, 1)\n",
    "\t\t\t\t\tval_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "\t\t\t\t\tval_total_samples += val_labels.size(0)\n",
    "\n",
    "\t\t\t# Average validation loss and accuracy\n",
    "\t\t\tval_loss /= len(val_data_loader)\n",
    "\t\t\tval_accuracy = 100 * val_correct_predictions / val_total_samples\n",
    "\t\t\tprint(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "\t\t\t# Save the best model weights based on validation accuracy\n",
    "\t\t\tif val_accuracy > best_accuracy:\n",
    "\t\t\t\tbest_accuracy = val_accuracy\n",
    "\t\t\t\tbest_weights = model.state_dict().copy()\n",
    "\t\t\t\ttorch.save(best_weights, './models/best_model.pth')\n",
    "\t\t\t\tprint(\"New best model saved as './models/best_model.pth'\")\n",
    "\t\t\tmodel.train()  # Return to training mode\n",
    "\n",
    "\t# Epoch-level loss and accuracy\n",
    "\tepoch_loss = running_loss / len(train_data_loader)\n",
    "\tepoch_accuracy = 100 * correct_predictions / total_samples\n",
    "\tprint(f\"Epoch {epoch+1}/{num_epochs} completed: Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\t\n",
    "\t# Update the scheduler for learning rate decay\n",
    "\tscheduler.step()\n",
    "\n",
    "# Save the final model weights\n",
    "torch.save(model.state_dict(), './models/final_model.pth')\n",
    "print(\"Final model saved as './models/final_model.pth'\")\n",
    "\n",
    "# Ensure best weights are also saved\n",
    "if best_weights is not None:\n",
    "\ttorch.save(best_weights, './models/best_model.pth')\n",
    "\tprint(\"Best model saved as './models/best_model.pth'\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
